{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "FaceMask_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpO_30OEFs0u"
      },
      "source": [
        "# Import all necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras import losses \n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import BatchNormalization\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyfcUo-qKoew",
        "outputId": "72a8226f-bb80-48b8-cb23-cc561705a9e3"
      },
      "source": [
        "# Mount google drive content\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKWD-yjSMTAz"
      },
      "source": [
        "# Unzip FaceMaskDetection dataset\n",
        "\n",
        "!unzip \"/content/drive/MyDrive/Datasets/FaceMaskDetection.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qvO_R13Fs03"
      },
      "source": [
        "# Setting paths for two classes\n",
        "\n",
        "with_mask = \"/content/data/with_mask\"\n",
        "without_mask = \"/content/data/without_mask\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0vGkSsMFs03",
        "outputId": "877785b4-06e0-4ea2-e537-581ef0421830"
      },
      "source": [
        "# Pack image data to np array\n",
        "\n",
        "with_mask_data = list()\n",
        "for file in tqdm(os.listdir(with_mask),position=0):\n",
        "    path  = os.path.join(with_mask,file)\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image,(64,64))\n",
        "    image = image.tolist()\n",
        "    with_mask_data.append(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3725/3725 [00:25<00:00, 145.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A1DceaQFs05",
        "outputId": "f5ae4207-0ecf-49e5-a528-85dcfa5abbc5"
      },
      "source": [
        "# Pack image data to np array\n",
        "\n",
        "without_mask_data = list()\n",
        "for file in tqdm(os.listdir(without_mask),position=0):\n",
        "    path = os.path.join(without_mask,file)\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image,(64,64))\n",
        "    image = image.tolist()\n",
        "    without_mask_data.append(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3828/3828 [00:17<00:00, 219.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-f1UsgvFs05"
      },
      "source": [
        "with_mask_data = np.array(with_mask_data)\n",
        "without_mask_data = np.array(without_mask_data)\n",
        "X = np.concatenate((with_mask_data,without_mask_data), axis = 0)\n",
        "Y = np.concatenate((np.ones(3725), np.zeros(3828)), axis = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDWoTit4Fs06"
      },
      "source": [
        "# Setting different train and test data\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc8SLahGFs06",
        "outputId": "0f27af5a-9dd3-4972-c8fc-309ce54f7268"
      },
      "source": [
        "# Print train and test data np array shape\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5664, 64, 64, 3)\n",
            "(1889, 64, 64, 3)\n",
            "(5664,)\n",
            "(1889,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kdxt03PTFs0_"
      },
      "source": [
        "# Face Mask Detection using CNN\n",
        "\n",
        "input_shape = (64, 64, 3)\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=64, kernel_size = (3,3), activation='relu',input_shape=input_shape,data_format='channels_last'))\n",
        "model.add(Conv2D(filters=64, kernel_size = (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())    \n",
        "model.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512,activation=\"relu\"))\n",
        "model.add(Dense(128,activation='sigmoid'))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6hzGJ6DFs0_",
        "outputId": "03b427e8-3895-4e15-f943-97149c80b549"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 30, 30, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 128)       147584    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 13, 13, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 13, 13, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 5, 5, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6400)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 6400)             25600     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 512)               3277312   \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,924,801\n",
            "Trainable params: 3,911,617\n",
            "Non-trainable params: 13,184\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6aQdwWHFs0_"
      },
      "source": [
        "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBt_eP9xUhQZ"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ozqn1mIJYB3l"
      },
      "source": [
        "train_gen = datagen.flow(X_train,y_train,batch_size=32)\n",
        "test_gen = datagen.flow(X_test,y_test,batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm-mA9b9ZO3V",
        "outputId": "8c99d690-5842-4cbc-c96a-c64b8946117b"
      },
      "source": [
        "history = model.fit(train_gen,\n",
        "                              epochs=20,\n",
        "                              steps_per_epoch = X_train.shape[0] // 32\n",
        "                              ,verbose=1,\n",
        "                              validation_data=test_gen,\n",
        "                              validation_steps = X_test.shape[0] // 32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "177/177 [==============================] - 303s 2s/step - loss: 0.3239 - accuracy: 0.8683 - val_loss: 0.4236 - val_accuracy: 0.7929\n",
            "Epoch 2/20\n",
            "177/177 [==============================] - 304s 2s/step - loss: 0.2586 - accuracy: 0.8939 - val_loss: 0.1925 - val_accuracy: 0.9306\n",
            "Epoch 3/20\n",
            "177/177 [==============================] - 306s 2s/step - loss: 0.2249 - accuracy: 0.9145 - val_loss: 0.1954 - val_accuracy: 0.9259\n",
            "Epoch 4/20\n",
            "177/177 [==============================] - 305s 2s/step - loss: 0.2118 - accuracy: 0.9153 - val_loss: 0.1822 - val_accuracy: 0.9341\n",
            "Epoch 5/20\n",
            "177/177 [==============================] - 304s 2s/step - loss: 0.1840 - accuracy: 0.9290 - val_loss: 0.2609 - val_accuracy: 0.8824\n",
            "Epoch 6/20\n",
            "177/177 [==============================] - 303s 2s/step - loss: 0.1713 - accuracy: 0.9333 - val_loss: 0.4828 - val_accuracy: 0.7294\n",
            "Epoch 7/20\n",
            "177/177 [==============================] - 303s 2s/step - loss: 0.1551 - accuracy: 0.9428 - val_loss: 0.2298 - val_accuracy: 0.9153\n",
            "Epoch 8/20\n",
            "177/177 [==============================] - 305s 2s/step - loss: 0.1411 - accuracy: 0.9474 - val_loss: 0.2400 - val_accuracy: 0.8976\n",
            "Epoch 9/20\n",
            "177/177 [==============================] - 303s 2s/step - loss: 0.1283 - accuracy: 0.9509 - val_loss: 0.3145 - val_accuracy: 0.8518\n",
            "Epoch 10/20\n",
            "177/177 [==============================] - 299s 2s/step - loss: 0.1255 - accuracy: 0.9541 - val_loss: 0.1022 - val_accuracy: 0.9718\n",
            "Epoch 11/20\n",
            "177/177 [==============================] - 297s 2s/step - loss: 0.1108 - accuracy: 0.9590 - val_loss: 0.1547 - val_accuracy: 0.9318\n",
            "Epoch 12/20\n",
            "177/177 [==============================] - 295s 2s/step - loss: 0.1153 - accuracy: 0.9597 - val_loss: 0.1074 - val_accuracy: 0.9671\n",
            "Epoch 13/20\n",
            "177/177 [==============================] - 296s 2s/step - loss: 0.1051 - accuracy: 0.9613 - val_loss: 0.0819 - val_accuracy: 0.9753\n",
            "Epoch 14/20\n",
            "177/177 [==============================] - 296s 2s/step - loss: 0.0948 - accuracy: 0.9657 - val_loss: 0.0818 - val_accuracy: 0.9765\n",
            "Epoch 15/20\n",
            "177/177 [==============================] - 297s 2s/step - loss: 0.0905 - accuracy: 0.9665 - val_loss: 0.2180 - val_accuracy: 0.9000\n",
            "Epoch 16/20\n",
            "177/177 [==============================] - 296s 2s/step - loss: 0.0866 - accuracy: 0.9703 - val_loss: 0.0656 - val_accuracy: 0.9824\n",
            "Epoch 17/20\n",
            "177/177 [==============================] - 296s 2s/step - loss: 0.0839 - accuracy: 0.9680 - val_loss: 0.0916 - val_accuracy: 0.9694\n",
            "Epoch 18/20\n",
            "177/177 [==============================] - 296s 2s/step - loss: 0.0832 - accuracy: 0.9693 - val_loss: 0.1056 - val_accuracy: 0.9635\n",
            "Epoch 19/20\n",
            "177/177 [==============================] - 295s 2s/step - loss: 0.0711 - accuracy: 0.9756 - val_loss: 0.0688 - val_accuracy: 0.9765\n",
            "Epoch 20/20\n",
            "177/177 [==============================] - 297s 2s/step - loss: 0.0678 - accuracy: 0.9744 - val_loss: 0.0400 - val_accuracy: 0.9894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX6mwn-vbjlY",
        "outputId": "f8e5661e-3f6a-492c-ac25-31d692947f3d"
      },
      "source": [
        "model.evaluate(test_gen,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 26s 432ms/step - loss: 0.1107 - accuracy: 0.9614\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11066458374261856, 0.9613552093505859]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmMVAYoBioxY",
        "outputId": "198bb6f5-7b85-477e-f46c-6390c7358443"
      },
      "source": [
        "model.save(\"FaceMaskModel\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: FaceMaskModel/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJK6dPm-thxW"
      },
      "source": [
        "# model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vEMe7rkDogM"
      },
      "source": [
        "model = keras.models.load_model(\"/content/FaceMaskModel\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15-LnYG_GIGl",
        "outputId": "885cea46-eaae-4d62-9e9e-16b698dcd1d9"
      },
      "source": [
        "model.evaluate(test_gen,verbose=1)[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60/60 [==============================] - 26s 432ms/step - loss: 0.1053 - accuracy: 0.9619\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.961884617805481"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "teZVLfeMFmvC",
        "outputId": "fb52e2de-b601-4e8a-adce-c599aedff8ab"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f7e09e33-4121-4ef1-82e7-ceb3a4ee12e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f7e09e33-4121-4ef1-82e7-ceb3a4ee12e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving haarcascade_frontalface_default.xml to haarcascade_frontalface_default.xml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kJ3oQFZMqn6s",
        "outputId": "fcacabf7-f030-4f0f-be1f-bfcd7acf9b1d"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive(\"FaceMask\", 'zip', \"/content/FaceMaskModel\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/FaceMask.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2nbDN7rpO2j"
      },
      "source": [
        "# import joblib \n",
        "# joblib.dump(model,\"FaceMaskDetectionModel.sav\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "font = cv2.FONT_HERSHEY_SIMPLEX \n",
        "  \n",
        "# org \n",
        "org = (50, 50) \n",
        "  \n",
        "# fontScale \n",
        "fontScale = 0.5\n",
        "   \n",
        "# Blue color in BGR \n",
        "color = (255, 0, 0) \n",
        "  \n",
        "# Line thickness of 2 px \n",
        "thickness = 2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "video_capture = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = video_capture.read()\n",
        "  \n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    faces = face_cascade.detectMultiScale(\n",
        "        gray,\n",
        "        scaleFactor=1.1,\n",
        "        minNeighbors=5,\n",
        "        minSize=(30, 30),\n",
        "        flags=cv2.CASCADE_SCALE_IMAGE\n",
        "    )\n",
        "\n",
        "    # Draw a rectangle around the faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        extracted_face = frame[y:y+h, x:x+w]\n",
        "        image = cv2.resize(extracted_face,(64,64))\n",
        "        image1 = np.array([image])\n",
        "        value = model.predict(image1)[0][0]\n",
        "        accuracy = model.predict(image1)[0][0]\n",
        "        class_name = \"\"\n",
        "        if(value==0):\n",
        "            class_name = \"Without Mask\"\n",
        "        elif(value==1):\n",
        "            class_name = \"With Mask\"\n",
        "        text = \"{} ({})\".format(class_name,accuracy)\n",
        "        final_image = cv2.putText(extracted_face,text,org,font,fontScale, color, thickness, cv2.LINE_AA)\n",
        "\n",
        "    # Display the resulting frame\n",
        "    cv2.imshow('Video', frame)\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# When everything is done, release the capture\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "jN-2ROjYJxOB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}